%%
%%
%% NSF requires minimum of 10pt font with margins on all sides of at least
%% 2.5cm.  No more than 15 characters (including spaces) per 2.5cm (avg).
%% No more than 6 lines of type w/in a vertical space of 2.5cm. 
%%
%%

\documentclass[12pt]{article}
\usepackage{epsfig}
%\usepackage{html}
%\usepackage{citesort}
\usepackage{overcite}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{times}
\usepackage{wrapfig}
%\usepackage[normal,footnotesize]{caption}
%\usepackage[normal,footnotesize]{}
\usepackage[small]{caption}

\setlength{\topmargin}{0cm}
%\setlength{\topmargin}{2.0cm}
\setlength{\evensidemargin}{0cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\headsep}{0cm}
\setlength{\headheight}{0cm}
\setlength{\marginparwidth}{0cm}
\setlength{\marginparpush}{0pt}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.7in}
\setlength{\footskip}{20pt}
\addtolength{\abovecaptionskip}{-3mm}
\parskip 3pt
%\setlength{\parindent}{0in}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}

%%%%%%% DEFINITIONS, ETC %%%%%%%%%%%
\def\ket#1{| #1 \rangle}
\def\bra#1{\langle #1 |}
\def\spinor#1{\chi_{#1}}
\def\creat#1{a_{#1}^{\dagger}}
\def\annih#1{a_{#1}}
\def\ud{\mathrm{d}}

\begin{document}

\setcounter{secnumdepth}{4}
%\renewcommand{\thesection}{}
\renewcommand{\thesubsection}{\arabic{subsection}}
\renewcommand{\thesubsubsection}{\arabic{subsubsection}}
%\addtocounter{subsection}{2}

%\section{Project Description}

%
% From the 2011 GPG:
%
%Plans for data management and sharing of the products of research.
%Proposals must include a supplementary document of no more than two pages
%labeled “Data Management Plan”. This supplement should describe
%how the proposal will conform to NSF policy on the dissemination and
%sharing of research results (see AAG Chapter VI.D.4), and may include:
%
%1. the types of data, samples, physical collections, software,
%curriculum materials, and other materials to be produced in the course
%of the project;
%
%2. the standards to be used for data and metadata format and content
%(where existing standards are absent or deemed inadequate, this should
%be documented along with any proposed solutions or remedies);
%
%3. policies for access and sharing including provisions for appropriate
%protection of privacy, confidentiality, security, intellectual property,
%or other rights or requirements;
%
%4. policies and provisions for re-use, re-distribution, and the
%production of derivatives; and
%
%5. plans for archiving data, samples, and other research products,
%and for preservation of access to them.
%
%Data management requirements and plans specific to the Directorate,
%Office, Division, Program, or other NSF unit, relevant to a proposal are
%available at: http://www.nsf.gov/bfa/dias/policy/dmp.jsp. If guidance
%specific to the program is not available, then the requirements
%established in this section apply.
%
%Simultaneously submitted collaborative proposals and proposals that
%include subawards are a single unified project and should include
%only one supplemental combined Data Management Plan, regardless of
%the number of non-lead collaborative proposals or subawards included.
%Fastlane will not permit submission of a proposal that is missing a
%Data Management Plan. Proposals for supplementary support to an existing
%award are not required to include a Data Management Plan.
%
%A valid Data Management Plan may include only the statement that no
%detailed plan is needed, as long as the statement is accompanied by a
%clear justification. Proposers who feel that the plan cannot fit within
%the supplement limit of two pages may use part of the 15-page Project
%Description for additional data management information. Proposers are
%advised that the Data Management Plan may not be used to circumvent
%the 15-page Project Description limitation. The Data Management Plan
%will be reviewed as an integral part of the proposal, coming under
%Intellectual Merit or Broader Impacts or both, as appropriate for the
%scientific community of relevance.

\subsubsection*{Data Management Plan}

The primary data to be generated by the proposed research project
consist of (a) software products, and (b) training and validation data
for machine learning models.

{\bf Software products:} During the development stages, this software
will be stored on secure computing systems at Georgia Tech, and also
on a private repository on the commercial site GitHub.  We use the
{\tt git} version control software to be able to track revisions and
revert to earlier versions if unwanted changes are introduced to the
code by accident.  Our internal servers are backed up regularly and
automatically using the {\tt rsnapshot} tool, and GitHub of course
backs up its own data.  Once mature, the code will be publicly released.
SAPT0-D capabilities will be released through the {\sc
Psi4} package, which has an interface to Grimme's {\sc dftd3} package
that performs the pairwise-atomic dispersion computation.  In the
previous grant period, we updated our license to the less restricted
GNU Lesser General Public License (LGPL) and intend to continue with
this license for future releases of {\sc Psi4}.  Code will be archived
indefinitely through our servers and also through our publicly-accessible
repository on GitHub.  We have used this approach successfully for the
{\sc Psi} software program for the last several years.

Machine learning improvements to SAPT0-D, e.g., SAPT0-D+$\Delta$ML,
will be released also through the {\sc Psi4} package and require no
additional dependencies. We anticipate models arising from SAPT0-D
improvements will not depend explicitly on training data, so can be
easily stored in very small models.

SAPT-ML software will exist as a stand-alone package written in Python3,
and it will be made open-source and freely available on GitHub. We
will use a GNU General Public License (GPL) so that interested users
can view and modify our code to advance SAPT-ML. While reference data
will be hosted externally (see below), all models will be available
with the codebase, along with a user-friendly interface for inferring
component energies from dimers in {\tt .xyz} format.  Models used in
SAPT-ML are not memory-extensive, only requiring up to about 100 MB,
which allows our production-level models to be hosted on GitHub with
the code itself.  All external dependencies, specifically TensorFlow2,
NumPy, Pandas, and HDF5, are free and can be easily installed. SAPT-ML
will be extensively documented for users who want to use provided models
in addition to building their own models from customized datasets.

Similar to SAPT-ML, improved force-fields of the PFF$\leftarrow$ML
type will also be an open-source Python3 package made freely available
under a GPL license and accessible via GitHub.  Our initial work will
make use of components of the IPML code, which also uses a GPL license.
We will provide all kernel matrices in {\tt.pkl} format used to construct
all models.  While we will always have models available on GitHub, Git
Large File storage (LFS) limits file sizes to 2 GB. Therefore, for any
production-level models we generate with our largest datasets, we will
externally host these files on our publicly-available web server. We will
provide documentation and interactive examples for users to interact
with the code on multiple levels. Firstly, users will easily be able
to take their own dimer coordinates and compute interaction energies,
with the only dependency being {\sc QML} which builds atomic descriptors
under-the-hood.  We will also provide procedures and documentation for
building custom ML models from users' own datasets, which requires the
additional prerequisites of {\sc Psi4} and Horton.  Our code being
freely-available and open source will facilitate the integration of
other researcher's physical models.

{\bf Training and validation data:} The proposed work will require the
generation of large amounts of data for training and validating the
machine learning models.  We will make this data publicly available,
because we think it will be very valuable to the community as
training/validation data for other projects as well.  Where feasible,
we will publish the data along with the journal papers we write as
part of this project.  Our practice is to include extensive Supporting
Information where relevant, providing Cartesian coordinates of key
molecular structures and tables of the raw energies that are used
to obtain the final quantities reported in papers.  Results from the
simulation data are backed up regularly and automatically by our group's
network file server.

Training and validation data for the SAPT-ML project will likely be too
extensive to exist solely within published Supplemental Information.
Specifically, this data encompasses 200,000 dimer computations and
requires approximately 3 GB for our preliminary data.  To make this data
publicly available, we will upload all geometries in {\tt .xyz} format
with corresponding SAPT component energies to our group's web server.

Additionally, dimer databases used to fit global parameters
in PFF$\leftarrow$ML will also require storage on the group web
server. This dimer database can be used to benchmark theories for
computing non-covalent interactions beyond the scope of training
ML models.  To train and test models in IPML used to infer atomic
parameters, a molecular database is required. In practice this database
will include several thousands of molecules ($\sim$ 8K or larger) in
addition to the corresponding reference parameters, e.g. multipoles,
atomic widths, etc., stored in a compressed format in the same repository
on the group web server.



\end{document}


